{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision import transforms\n",
    "import pytorch_msssim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import lr_scheduler\n",
    "import gc\n",
    "from time import sleep\n",
    "import math\n",
    "\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Drone:\n",
    "    def __init__(self, id, x, y, z):\n",
    "        self.id = id\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoded_space_dim = encoded_space_dim\n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 4, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 4, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 4, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(8 * 8 * 128, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        #z_mean = self.encoder_lin(x)\n",
    "        #z_log_var = self.encoder_lin(x)\n",
    "        #N = torch.normal(0, 1, size=(z_log_var.size()[0], self.encoded_space_dim))\n",
    "        #N = N.to(device)\n",
    "        #print('N: ', N.shape, ' z_log_var: ', z_log_var.shape)\n",
    "        return x #(torch.exp(z_log_var / 2) * N + z_mean), z_mean, z_log_var\n",
    "\n",
    "def load_embeddings():\n",
    "    image_path = '../map/test_map_crop.png'\n",
    "    full_map = cv2.imread(image_path)\n",
    "    full_map = cv2.cvtColor(full_map, cv2.COLOR_BGR2RGB)\n",
    "    # координаты тайлов\n",
    "    height, width, _ = full_map.shape\n",
    "    step = 50\n",
    "    tile_size = 300\n",
    "    coord_dataset = pd.DataFrame(columns = ['x', 'y'])\n",
    "    for x in range(0, width - tile_size, step):\n",
    "        for y in range(0, height - tile_size, step):\n",
    "            coord_dataset.loc[len(coord_dataset.index)] = [x, y]\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, full_map, coord_dataset, tile_size, transform=None):\n",
    "            self.mapa = full_map\n",
    "            self.coords = coord_dataset\n",
    "            self.tile_size = tile_size\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.coords.index)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            x = self.coords.iloc[idx]['x']\n",
    "            y = self.coords.iloc[idx]['y']\n",
    "            image = full_map[y:y+tile_size, x:x+tile_size]\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, (x, y)\n",
    "    encoder = Encoder(encoded_space_dim=256)\n",
    "\n",
    "    best_encoder = torch.load('../models/best_encoder_02_08.pth', weights_only=True)\n",
    "    encoder.load_state_dict(best_encoder)   \n",
    "      \n",
    "\n",
    "    batch_size = 1\n",
    "    train_dataset = CustomDataset(full_map=full_map[:, :5000], coord_dataset = coord_dataset, tile_size = tile_size, transform=transforms.ToTensor())\n",
    "    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    encoder.to(device)\n",
    "    encoder.eval()\n",
    "    embedings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            # if i == 1:\n",
    "            #     break\n",
    "            inputs, label = data\n",
    "            # print(\"Input: \", inputs)\n",
    "            # print(\"Labels: \", labels)\n",
    "            # print(\"Input: \", inputs.shape)\n",
    "            inputs = inputs.to(device)\n",
    "            coded= encoder(inputs)\n",
    "    \n",
    "            inputs = inputs.cpu().numpy().flatten().tolist()\n",
    "            coded = coded.cpu().numpy().flatten().tolist()\n",
    "\n",
    "            \n",
    "            # print(coded)\n",
    "            # print(coded.shape)\n",
    "            embedings.append(coded)\n",
    "            labels.append(label)\n",
    "            # print(\"---------------\")\n",
    "            \n",
    "\n",
    "    print(\"Emb Amount: \", len(embedings))\n",
    "    print(\"Emb: \", embedings[0:3], \"...\")\n",
    "    return labels, embedings\n",
    "\n",
    "def image_to_tensor(drone):\n",
    "    # пока использую статичное изображение, потом буду получать от камеры\n",
    "    # step = 50\n",
    "    tile_size = 300\n",
    "    x = drone.x\n",
    "    y = drone.y\n",
    "    full_map_image_path = '../map/test_map_crop.png'\n",
    "    full_map = cv2.imread(full_map_image_path)\n",
    "    fpv_image = full_map[y:y+tile_size, x:x+tile_size]\n",
    "    fpv_image = cv2.cvtColor(fpv_image, cv2.COLOR_BGR2RGB)\n",
    "    transform=transforms.ToTensor()\n",
    "    fpv_image = transform(fpv_image)\n",
    "    fpv_image = fpv_image.unsqueeze(0)\n",
    "    print(\"Image shape:\",fpv_image.shape)\n",
    "    return fpv_image\n",
    "\n",
    "def image_to_embeding(inputs):\n",
    "     \n",
    "    encoder = Encoder(encoded_space_dim=256)\n",
    "    encoder.to(device)\n",
    "    best_encoder = torch.load('../models/best_encoder_02_08.pth')\n",
    "    encoder.load_state_dict(best_encoder)  \n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        coded= encoder(inputs)\n",
    "        coded = coded.cpu().numpy()\n",
    "        print(\"Image coded emb shape:\",coded.shape)\n",
    "        return coded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emb Amount:  11766\n",
      "Emb:  [[840253.5625, -1513909.0, 1465532.5, 1046405.75, -134882.765625, 2214575.5, -2317032.5, 2661200.75, -1264200.5, 1293493.75, -3086850.5, 702301.4375, 1097598.875, -1424556.0, 3579973.5, 165845.203125, -1368620.125, 1397344.125, 679553.4375, -1053808.25, 2182731.75, 115009.0625, -1413767.5, -2943146.5, -1159491.625, 1002681.75, 2540691.5, -931672.6875, 1245693.75, -1178244.875, -1150855.75, 1715002.0, 1947900.0, 1623845.0, -905912.3125, -2948291.0, -482880.78125, 521237.3125, -1283252.875, 2390733.5, -579185.8125, -521592.75, -1454976.0, -2690882.75, -1318492.375, 330434.34375, 779508.1875, -2160387.75, 1921539.625, -877820.625, 1116261.5, 2369450.5, -1792720.75, -233966.75, -861752.8125, -739302.125, 594537.6875, 1472445.25, -2379138.25, 1851809.25, -1776061.125, 1944422.375, -2134642.75, 1085546.5, 1987648.25, 1196873.75, 2177309.25, 1185854.75, 1389903.0, -3552451.0, -2150870.5, -1363709.75, 29298.701171875, -2383970.5, 1848058.25, -3079708.5, 871963.9375, -1862285.5, -3581914.25, 2385224.0, -493564.96875, 619057.25, -1365755.25, 1077868.625, 1241350.125, -938428.375, 912560.9375, 939496.4375, 1184020.125, 984375.1875, 2239692.25, 838650.0625, 2964411.75, -1836723.75, -269276.59375, -259769.15625, -1396252.625, 1996011.875, 1830561.5, -1205586.75, 652684.8125, 957729.8125, 3620818.0, 687095.8125, 1488191.625, 937450.5, 582168.6875, 185225.21875, -159552.5625, -1898087.875, 1220798.5, 15210.1591796875, -1529494.375, -1380438.0, -1836277.5, -3222448.0, 34297.6953125, -419937.84375, -860334.75, 860569.0, 820671.625, -2199926.0, -512613.4375, -2457059.0, 1099997.75, 1087998.75, 1386510.375, -768886.0625, -2217673.0, 356478.53125, -1854617.875, -1478057.0, -791342.75, -694793.5, -3302767.75, 673428.6875, -3600802.5, 1507129.75, 559080.4375, 715771.875, -1767106.625, 1217728.0, -3469846.5, -3306987.5, 938672.8125, 1680727.125, 1470257.0, 1631196.0, 1555200.75, -1227074.75, -287189.25, -2135724.5, 990468.1875, -2001185.25, 1469430.75, 1434565.375, -4805400.0, -121765.65625, -806685.5625, -1275516.375, 1010512.1875, -2358046.25, 95499.65625, 1022842.375, -920140.875, 329557.1875, -860097.875, -446973.71875, -1183043.125, -859402.0, -2037399.375, 1006625.0625, 737177.4375, -1996105.75, 1145728.125, 743393.0625, -545886.1875, 782804.375, -3048633.75, 1923524.75, -1359316.125, -183839.203125, 789163.75, 380757.78125, 2338946.5, 3467855.0, 698151.1875, 1363808.0, -583374.25, -1533257.75, -494270.25, -1548559.375, -91886.9453125, -1153235.875, 941131.8125, 65460.21875, -2624988.75, 2970842.25, -1713381.875, 271346.5625, 2861223.25, -739634.75, 1675052.25, -1069310.75, 1915820.375, 1153319.25, 3328564.25, 1133220.0, -774116.875, -1248329.5, 3536681.75, 1346297.5, -505185.21875, 468254.3125, 291544.40625, 613794.25, 2573913.25, 1027723.8125, -2113424.5, 2670041.5, 2478488.75, -177357.3125, 1104994.5, -876166.1875, -1383021.625, -2469244.75, -1297922.375, -1470440.125, -811699.75, 2141890.5, -1389567.75, 2657886.0, -828741.125, 2775591.25, -3229956.0, 1446633.0, 3190941.5, -2621363.75, -639663.4375, 1867085.0, -1254254.5, 523280.125, -1851099.625, -1670260.5, 1569717.25, -3534710.25, 698542.5625, -2389071.75, -1341626.375, 297545.875, 834266.75, 928599.6875, -1005217.6875, 1573706.5, -792914.375, -2025279.375], [-354057.28125, -70973.484375, -103203.359375, -29903.544921875, 321524.34375, -350466.53125, -161398.640625, -389253.4375, 39380.2578125, -148269.625, 191175.578125, 117840.6796875, -253273.28125, 156685.78125, 85005.546875, 237550.15625, 571955.0, 95003.0625, 63695.87109375, 136176.03125, 99115.2109375, -335800.5, 182802.140625, 2203.468994140625, 81675.328125, -198789.453125, 310487.84375, 333996.53125, -235261.703125, 35366.1484375, 252027.515625, -60527.12890625, 72643.59375, 7203.64453125, -391397.125, 171316.703125, -99203.0, -72504.90625, -108604.5625, 48557.25390625, -28510.80078125, -97745.859375, 196689.421875, 347730.6875, -563012.1875, -68064.0859375, -40620.87890625, 240445.96875, -247389.859375, 81894.734375, 80457.59375, -349120.0625, -155430.8125, 133208.203125, 116982.4296875, -588709.0, 121395.0390625, -86846.0625, -108974.2890625, 97822.921875, 339786.03125, -386018.59375, 302288.875, -52676.16796875, -245286.765625, -257538.6875, 175093.796875, 142141.96875, -116986.4140625, -100597.46875, 179679.625, -56284.5703125, 235624.703125, -1627.5115966796875, -154747.03125, 95769.15625, -59904.2421875, 195634.015625, -71919.484375, -373051.75, 371760.15625, -27644.509765625, 288445.34375, -13846.7216796875, 263122.875, 27819.6171875, 58679.484375, -127940.8203125, -150723.53125, 13812.662109375, -250029.125, -68306.234375, -2138.56982421875, 912121.6875, -135961.875, 169170.5625, 347520.0, -110361.4609375, -515871.1875, 311530.625, -91678.1640625, -197733.71875, -761984.3125, -57711.76171875, 43983.30859375, 31662.89453125, 11104.580078125, -282394.53125, 364236.875, 9445.9599609375, 21630.33203125, -361433.15625, 208119.3125, 230234.0625, 265566.46875, 151663.515625, 147813.09375, 177765.828125, -319702.0, -38662.6953125, 15072.1484375, 691841.8125, 95156.3515625, -138574.71875, -213434.421875, -907870.0625, -56000.15625, 72589.7421875, 186063.53125, -1946.53466796875, -277058.46875, -551321.75, 63540.75, 161182.515625, -131209.953125, -276406.65625, -38169.1171875, 176239.6875, -487136.875, -286479.59375, 57750.24609375, -64872.7578125, 44402.74609375, -163584.78125, -148141.390625, 92309.546875, 349654.75, -54257.97265625, -13750.60546875, -156592.046875, -110195.078125, -417281.4375, -442918.25, 311186.53125, -379078.75, -591532.0, -846570.3125, 98259.734375, 261679.078125, 13357.369140625, -716572.1875, 47710.55859375, 39148.3984375, 5250.27294921875, 224637.734375, -507774.25, 71480.1328125, -242822.875, 11894.3984375, -1524.091064453125, 557009.3125, -255461.171875, 48873.52734375, 59317.5078125, -176464.6875, -24272.1171875, 167564.734375, -233477.328125, -173379.71875, -558193.75, -1711.6785888671875, 429583.40625, -225163.6875, -295894.625, -589193.9375, 239098.9375, 297166.0, -452053.46875, 64374.1796875, 192459.375, 288475.03125, 107560.6171875, 176168.0625, -300145.59375, -134201.71875, -56330.46875, 82525.6796875, -308218.09375, 249781.03125, -57656.2421875, -21922.189453125, 303452.65625, -136525.875, 216192.921875, -520921.8125, 370273.25, 581638.125, -58897.8515625, -341178.21875, -459823.84375, 241127.3125, 316654.28125, 113091.296875, -219720.359375, 87792.6953125, -509221.53125, -27063.548828125, 76206.953125, -482173.25, -235190.71875, 159552.21875, -120858.765625, -420475.75, -167977.125, 142707.71875, 64573.26171875, 44749.75, 174167.609375, 237092.40625, -923753.5625, -24580.630859375, 487615.78125, -137192.890625, 117112.4296875, -34903.203125, 31705.26953125, -408612.59375, 208494.390625, 532830.75, -598371.625, 61675.015625, 67849.3984375, 109412.453125, 119072.7734375, -207718.546875, -52501.046875, 13809.078125, 399800.03125, -150629.078125, -292610.125, -72701.2734375, 133393.40625, 427087.5, -248018.390625, 89352.5859375, -132246.421875], [32768.11328125, 48485.76953125, -1092911.125, 771363.1875, -1490162.625, 2765814.75, 1788359.0, 2879922.5, 697940.3125, -622136.5, -2884203.5, 72487.3359375, -753032.1875, 1385021.25, 2769875.75, -366887.28125, 551811.375, 1076974.25, -279202.21875, 148349.5625, -1308511.5, -219100.46875, 396540.96875, -564203.375, -1046759.0625, 424122.90625, -1515654.0, 1017436.1875, -614540.4375, -1164215.125, -1735240.75, -280158.0625, -1395709.25, 843222.8125, -719215.875, -2213103.5, -194479.796875, 627283.9375, -198287.3125, -1621331.0, 1578620.75, 811854.0625, -2342058.0, -2552362.0, 2576859.75, -252888.28125, -34068.23828125, 713384.8125, 1704876.875, -464242.5625, 1123574.75, 2135668.75, -1413804.75, 1016255.4375, -601361.4375, 2257494.0, -153326.828125, 1395828.75, 1207389.375, -1372073.375, -2440382.0, -539574.8125, 853558.1875, -242854.5, 1566460.625, -104209.8203125, -1832258.5, -2464513.0, -557245.8125, -3148465.5, 1504509.875, 1321355.375, -564293.6875, -1053405.375, -1927806.25, -2644720.25, 1363778.125, 784965.5, -1634904.75, 2987706.0, -1415668.75, -792533.875, 740466.875, 715044.0, -1510066.125, -807151.0625, 880506.3125, -754363.4375, -1103610.625, 951535.4375, 1188942.375, 458139.625, -192301.421875, 2152300.0, 1406591.0, -52047.63671875, -2921597.0, -920279.25, -628523.625, 977873.0625, 656012.625, -133099.25, -2551130.0, -154285.8125, 298844.59375, 670804.9375, 662189.5625, 214852.3125, -1070063.75, -1024155.1875, -658642.3125, 177289.625, 779874.6875, -1997459.5, 499232.78125, -1960235.375, 216897.5, -1554461.75, -165092.109375, -190085.046875, 201866.09375, -616924.3125, 555065.5625, -2603040.5, -1621652.5, -810177.625, 1084715.375, -779503.875, -491261.03125, 1187283.0, -1201545.0, 2729766.5, 180892.96875, -657871.1875, 1076558.5, -81447.4609375, -2442088.0, -1711688.875, 1131056.0, 1096679.875, -1612623.0, 1461781.625, -2455988.75, -2826440.0, 861858.8125, 1773225.5, 939435.25, 1874544.0, -2297817.25, 1261857.125, 731131.625, -1998454.0, -543194.4375, -973097.5625, 981359.9375, 587644.5625, 1740046.375, -765322.9375, -1040792.3125, 1018887.0, 763767.9375, 646910.9375, -596348.5, 1043144.625, 782264.25, -1469127.875, -1245212.75, -238165.828125, 2633504.5, -843682.875, 654226.9375, -1075058.5, 552745.375, 908716.4375, 1992040.125, 3114.718017578125, 599810.625, -386458.0625, -1691963.125, 3084660.5, -1158982.125, -2103781.5, 446969.5, 1004529.4375, 2813764.75, 2887056.5, -1139476.5, -599183.375, -921301.0625, -1648229.125, 148333.578125, -1651282.5, -236061.515625, 1711459.5, -1011022.8125, 2320361.0, 1073151.125, 2807977.75, -2367967.75, 1049834.625, 1856065.75, -1157293.25, -1067725.25, -160477.359375, 2364824.5, -2469309.0, 1168105.75, 742860.1875, -355907.53125, -1143073.25, 2739602.75, 718276.875, -738232.6875, 827103.125, 387180.4375, 16484.587890625, -100343.609375, 771871.1875, 2293762.5, 795883.9375, -938809.6875, 257532.421875, -855597.6875, -579137.75, 827245.9375, 1902312.625, -579495.5, 839078.6875, -2339728.75, -1134817.5, 1628142.625, -2506640.5, 1698489.375, -1070180.5, -3344142.0, -1463623.5, 2331702.5, -1621980.0, 215198.1875, 2683412.5, -1690366.75, 706787.1875, -2073246.75, -398877.46875, -338875.5625, -719481.5, 564662.3125, -2015625.0, 441408.40625, 913452.5, -442374.6875, -1679986.0, -2437342.5, 4402.86962890625, -1141104.75, -289813.15625]] ...\n"
     ]
    }
   ],
   "source": [
    "# загржуам эмбединги в память\n",
    "labels, data = load_embeddings()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ключ-значение для меток\n",
    "embedings = dict(zip(map(tuple,data), labels))\n",
    "\n",
    "# Преобразуем embeddings в DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Вычисляем ковариационную матрицу для embedings и инвертируем её\n",
    "cov_matrix = np.cov(df.T)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "\n",
    "# drone start coords\n",
    "drone = Drone(0, 333, 777, 0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearbyAreaCheck(drone, embedings, embeding_vector):\n",
    "    nearbyDelta = 300\n",
    "    x = embedings[tuple(embeding_vector)][0]\n",
    "    y = embedings[tuple(embeding_vector)][1]\n",
    "    if abs(x-drone.x) < nearbyDelta and abs(y-drone.y) < nearbyDelta:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 3, 300, 300])\n",
      "Image coded emb shape: (1, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4718/1534400846.py:176: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_encoder = torch.load('/media/kravtandr/SSD_1TB/Drone_nav/maks/best_encoder_02_08.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min mahal:  9.003372880059008\n",
      "New Drone coords:  [tensor([350]), tensor([750])]\n",
      "Real Drone coords:  333 777\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "for i in range(1):\n",
    "    # get image from camera\n",
    "    fpv_image = image_to_tensor(drone)\n",
    "\n",
    "    # image to encoder\n",
    "    encoded_image = image_to_embeding(fpv_image).flatten()\n",
    "\n",
    "    min_mahalanobis_distance = np.inf\n",
    "    closest_embeding_vector = None\n",
    "    # тут нужно потом сравнивать не со всеми а только с ближайшими\n",
    "    for embeding_vector in data:\n",
    "        if nearbyAreaCheck(drone, embedings, embeding_vector):\n",
    "            mahalanobis_distance = distance.mahalanobis(encoded_image, embeding_vector, inv_cov_matrix)\n",
    "            # print(mahalanobis_distance)\n",
    "            if mahalanobis_distance < min_mahalanobis_distance:\n",
    "                min_mahalanobis_distance = mahalanobis_distance\n",
    "                closest_embeding_vector = embeding_vector\n",
    "\n",
    "    print(\"Min mahal: \",min_mahalanobis_distance)\n",
    "    print(\"New Drone coords: \",embedings[tuple(closest_embeding_vector)])\n",
    "    print(\"Real Drone coords: \", drone.x, drone.y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
